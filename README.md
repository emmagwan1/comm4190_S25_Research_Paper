# COMM 4190 Final Project: LLMs and Grief Communication with Children

## Project Title:
**Implications of Using LLMs to Explain Bereavement to Children**

## Overview

This project explores whether large language models (LLMs) like ChatGPT can responsibly assist caregivers in explaining the death of a loved one to a child. It evaluates the developmental, ethical, and emotional stakes of using AI tools in highly sensitive grief-related conversations.

While LLMs may help draft clear, age-appropriate language, this paper argues that their use must be carefully limited. These tools cannot substitute the presence, emotional intelligence, and accountability of human caregivers. The paper uses qualitative analysis of prompt outputs and draws from research in developmental psychology, grief communication, and human-computer interaction.

## Contents

- **Introduction:** Framing the communicative challenge and role of LLMs.
- **Literature Review:** Understanding childhood development and the ethics of AI in emotional contexts.
- **Methodology:** Analysis of ChatGPT-generated responses to caregiver grief prompts.
- **Findings:** Evaluation of linguistic clarity, emotional resonance, and limitations of AI output.
- **Discussion:** Affordances, risks, and developmental challenges of AI-mediated grief conversations.
- **Conclusion:** LLMs can assist—but not replace—relational, human-centered grief communication.

## Methodology

One grief-related prompt was input into ChatGPT-4, simulating a caregiver asking how to explain death to a child of varying age and relational context. Each AI-generated response was evaluated based on:

- Developmental appropriateness  
- Emotional sensitivity  
- Clarity and metaphor use  
- Presence of misleading euphemisms  

## Key Findings

- LLMs provide useful linguistic scaffolding and emotionally sensitive phrasing.
- They allow low-stakes rehearsal for caregivers unsure how to start a hard conversation.
- However, they lack relational awareness, feedback adaptation, and moral accountability.
- Over-reliance on AI could lead to emotional distance and loss of relational depth in families.
- There are significant privacy and ethical risks in inputting sensitive family information into commercial AI systems.

## References

Notable sources include:

- Piaget (1952), Nagy (1948), and Bluebond-Langner (1978) on child cognitive development and death.
- Christ (2000), Worden (1996), and Balk & Corr (2009) on grief communication strategies.
- Chen et al. (2024) on EmotionQueen, a benchmark for evaluating LLM empathy.
- Gnewuch et al. (2022) and OpenAI (2023) on AI emotional simulation and risk disclosures.

Full references are provided in the bibliography section of the attached paper.

## File

- [`Comm_4190_Final_Paper.pdf`](Comm%204190%20Final%20Paper!.pdf): Full final submission (including bibliography)

## Author

- **Emma Gwan-Nulla** | COMM 4190 | Spring 2025

## Disclaimer

This paper is a student research project submitted for academic credit. It does not endorse the unsupervised use of AI for grief counseling or therapeutic communication with children.



# COMM4190 Spring 2025 - Research Project

* Use this repository for your Research Project



